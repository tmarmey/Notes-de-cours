\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\graphicspath{{../Images/}}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{subfig}
\usepackage{float}
\usepackage{xcolor}
\usepackage{listings}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}

\lstset{frame=tb,
  backgroundcolor=\color[rgb]{0.93,0.93,0.93},
  language=Python,
  aboveskip=3mm,
  belowskip=3mm,
  showstringspaces=false,
  columns=flexible,
  basicstyle={\small\ttfamily},
  numbers=none,
  numberstyle=\tiny\color{gray},
  keywordstyle=\color{blue},
  commentstyle=\color{dkgreen},
  stringstyle=\color{mauve},
  breaklines=true,
  breakatwhitespace=true,
  tabsize=3
}

\author{Thibaut Marmey}

\title{Notes de cours CADL - session-2}

\begin{document}
	\maketitle

\begin{scriptsize} \begin{itemize}
\item The basic components of a neural network
\item How to use gradient descent to optimize parameters of a neural network
\item How to create a neural network for performing regression
\end{itemize}\end{scriptsize}

\begin{normalsize}
\tableofcontents
\end{normalsize}

\section{Introduction}
\subsection{Generalities}
\begin{itemize}
\item Use data and gradient descent to teach the network what the values of the parameters of the network should be.
\item Idea of machine learning : letting the machine learn from the data.
\item We are interested in letting the computer figure out what representations it needs in order to better describe the data and some objective we've defined.
\end{itemize}
\subsection{Gradient Descent}
\begin{itemize}
\item Operation of the network are meant to transform the input data into something meaningful that we want the network to learn about.
\item Parameters of the NW are random so output is random as well.
\item If we need specific output, we can use "Gradient Descent" : way to optimize set of parameters.
\end{itemize}
\subsection{Defining Cost}
\begin{itemize}
\item Mesure of the "error"
\item Exemple : recognize apple or orange. Random network spit ou random 0s or 1s for apples and oranges. We can define :
\begin{itemize}
\item if the network predicts a 0 for an orange, then the error is 0. If the network predicts a 1 for an orange, then the error is 1. 
\item And vice-versa for apples. If it spits out a 1 for an apple, then the error is 0. If it spits out a 0 for an apple, then the error is 1. 
\end{itemize}
\item Defining error in terms of our parameters :
\begin{equation} error = network(image) - true\_label 
\end{equation}
\begin{equation} network(image) = predicted\_label
\end{equation}
\begin{equation} E = f(X) - y
\end{equation}
\end{itemize}
\subsection{Minimizing Error}
\begin{itemize}
\item Feed the network many images (100 for e.g) to see what the network is doing on average.
\item Changing network's parameters can have effect on the error.
\item The error provides a "training signal" or a measure of the "loss" or our network.
\item Assumptions in assuming our funtion is continuous and differentiable. 
\item Gradiant descent in a nutshell : "Error", "Cost", "Loss", or "Training Signal"
\end{itemize}
\subsection{Backpropagation}
\begin{itemize}
\item  The gradient is just saying, how does the error change at the current set of parameters.
\item To figure out what is the gradiet we use backpropagation. Whatever differences that output has with the output we wanted it to have, gets \textit{backpropagated} to every single param in our network.
\item Backprop is an effective way to find the gradient. Uses the \textit{chain rule} to find the gradian of the error.
\item \textit{y = mx + b} linear function. The slope or gradian is \textit{m}.
\item The process described : 
\begin{equation} \theta = \theta - \eta * \nabla_\theta * J(\theta)
\end{equation}
\begin{itemize}
\item $\theta$ : parameters
\item $\nabla$ : gradient, with repect to parameters $\theta$, $\nabla_\theta$
\item J : error
\item $\eta$ : learning rate describes how far along this gradient we should travel, typically value between 0.01 to 0.00001
\end{itemize}
\end{itemize}
\subsection{Local Minima/Optima and learning Rate}
\begin{itemize}
\item Dilemma : find a local or global minima.
\item The NW may have million of parameters, so the problem becomes more and more difficult.
\item Wize choice of the learning rate : 
\begin{itemize}
\item To small we dont get any better cost where we started
\item To big the cost goes up and down
\end{itemize} 
\end{itemize}

\section{Creating a Neural Network}
\subsection{Exemple with sine wave}
\begin{itemize}
\item Input X output y
\item Here te input is values in an interval instead of images like before.
\item The exemple is to create sine wave with uniform noise and create a neural network that is able to discover the sine wave.
\begin{lstlisting}
# Create data : sine wave with random noise in the interval
n_obs = 1000
xs = np.linscape(-n, n, n_obs)
ys = np.sin(xs) + np.random.uniform(-0.5,0.5,n_obs)
plt.scatter(xs, ys)
\end{lstlisting}
\item Train the NW to ginve any value on the x axis and have the value it should be on the y axis. (fundamental idea of regression : predicting some continuous output value given some continuous input value)
\end{itemize}
\subsection{Defining cost}
\begin{itemize}
\item Use of placeholder to define input and output values. Those variables will filled at the computation of the graph.
\begin{lstlisting}
X = tf.placeholder(tf.float32, name='X')
Y = tf.placeholder(tf.float32, name='Y')
\end{lstlisting}
\item Create session and define the parameters center and close to 0 with \\
\textit{tf.random\_normal(nb\_values, stddev=).eval()}
\begin{lstlisting}
sess = tf.InteractiveSession()
n = tf.random_normal([1000], stddev=0.1).eval()
\end{lstlisting}
\item Create \textbf{varaibles} using \textit{tf.Variable}, it does need an initial value or we can call an initializer.
\item Define two \textit{tf.Variable} for weight and bias
\begin{lstlisting}
W = tf.Variable(tf.random_normal([1], dtype=tf.float32, stddev=0.1), name='weight')
B = tf.Variable(tf.constant([0], dtype=tf.float32), name='bias')
# Scale input placholder X
Y_pred = X * W + B
\end{lstlisting}
\item Use gradient descent to lean what the best value of \textit{W} and \textit{b}.
\item Before that we have to know how to measure what the \textit{best} mean for what we try to do.
\item Let's define the absolute \textit{distance(val1, val2)} from the predicted value to the assumed sine wave value.
\begin{lstlisting}
cost = distance(Y_pred, tf.sin(X))
\end{lstlisting}
\item We calculate the mean of the cost we have for every observation
\begin{lstlisting}
cost = tf.reduce_mean(distance(Y_pred, tf.sin(X))
\end{lstlisting}
\end{itemize}
\subsection{Training Parameters}
\begin{itemize}
\item Use tensorflow optimizer 
\begin{lstlisting}
optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.01).minimize(cost)
\end{lstlisting}
\item Run the optimizer
\begin{lstlisting}
with tf.Session() as sess:
   #initilization of all the tf.Variable
   sess.run(tf.global_varables_initializer())
   prev_training_cost = 0.0
   for it_i in range(n_iterations):
      sess.run(optimizer, feed_dict={X:xs, Y:ys})
      training_cost = sess.run(cost, feed_dict={X:xs}) #...,session=sess)
      
      # each 10 iterations
      if it_i % 10 == 0:
         ys_pred = Y_pred.eval(feed_dict={X:xs})
         # print stuff like training_cost and plots
      
      if np.abs(prev_training_cost - training_cost < 0.000001:
         break # if local minima found
        
      prev_trianing_cost = training_cost
\end{lstlisting}
\item The output doesn't look like a sine wave at all. Actually it's only a line.
\item Training vs Testing : Have to learn more about the different between training and testing networks.
\end{itemize}
\subsection{Stochastic and Mini Batch Gradient Descent}
\begin{itemize}
\item Tricks to find the best local minima : using \textit{mini-batches} of size \textit{batch\_size}.
\begin{lstlisting}
idxs = np.arrange(100) # it will be changed to make it random
batch_size = 10
n_batches = idxs // batch_size
\end{lstlisting}
\item Look some random subset of the datase because neural networks love order and would use it to its advantage. But order is irrelevant to our problem.
\begin{lstlisting}
idxs = np.random.permutation(idxs)
\end{lstlisting}
\item Generalise the entire dataset. We modify the code which runs the optomizer to include the mini-batches program.
\begin{lstlisting}
idxs = np.random.permutation(range(len(xs)))
n_batches = len(idxs) // batch_size
for batch_i in range(n_batches):
   idxs_i = idxs[batch_i * batch_size: (batch_i+1) * batch_size]
   sess.run(optimizer, feed_dict={X:xs[idxs_i], Y:ys[idxs_i]})
training_cost = sess.run(cost, feed_dict={X:xs, Y:ys})
\end{lstlisting}
We get a better result : the line has a curve but it doesn't look like a sine wave.
\item This method is :
\begin{itemize}
\item Mini-batches : small pieces of data where we perform gradient descent
\item Stochastic : the order of the data is dandomized
\end{itemize}
\item Use a function of training
\begin{lstlisting}
def train(X, Y, Y_pred, n_iterations=100, batch_size=200, learning_rate=0.02):
\end{lstlisting}
\item To get better result we can have a bigger set of parameters.
\item We are going to multiply our input by 100 values, creating an "inner layer" of 100 neurons.
\begin{itemize}
\item Define \textit{tf.Variables} : Weights (multiplication) and biais (addition)
\begin{lstlisting}
n_neurons = 100
W = tf.Variable(tf.random_normal([1,n_neurons], stddev=0.1))
b = tf.Variable(tf.constant(0, dtype=tf.float32, shape=[n_neurons])
\end{lstlisting}
\item Operation with matrix and add every neuron's output
\begin{lstlisting}
h = tf.matmul(tf.expand_dims(X, 1), W) + b)
Y_pred = tf.reduce_sum(h, 1)
\end{lstlisting}
\item Retrain with new Y\_pred
\begin{lstlisting}
train(X, Y, Y_pred)
\end{lstlisting}
\end{itemize}
\item It takes longer to compute and the result is not better. Our function is still linear but the cost is going up and down : good signe = we can reduce the learning rate
\item Input's Representation : important to consider the kind of input we are working on. We don't treate the types of data in the same way like :
\begin{itemize}
\item sound using discrete fourier transform
\item text using word histograms
\end{itemize}
\end{itemize}
\subsection{Over vs. Underfitting}
\begin{itemize}
\item To approximate curve function we use polynomial function. We will try to learn the influence of each degree of this function
\end{itemize}



\end{document}
